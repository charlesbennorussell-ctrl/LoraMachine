{
  "permissions": {
    "allow": [
      "Bash(dir:*)",
      "Bash(python:*)",
      "Bash(venv/Scripts/python:*)",
      "Bash(where:*)",
      "Bash(\"/c/Users/benno/AppData/Local/Programs/Python/Python310/python.exe\" -m venv venv)",
      "Bash(\"D:/CTRL_ITERATION/flux-lora-pipeline/backend/venv/Scripts/python.exe\" -m pip install --upgrade pip wheel setuptools)",
      "Bash(\"D:/CTRL_ITERATION/flux-lora-pipeline/backend/venv/Scripts/pip.exe\" install:*)",
      "Bash(npm install:*)",
      "Bash(\"D:/CTRL_ITERATION/flux-lora-pipeline/backend/venv/Scripts/pip.exe\" install -r requirements.txt)",
      "Bash(\"D:/CTRL_ITERATION/flux-lora-pipeline/backend/venv/Scripts/pip.exe\" install fastapi uvicorn[standard] python-multipart websockets pydantic diffusers transformers accelerate safetensors peft datasets wandb huggingface-hub sentencepiece protobuf pyyaml tqdm opencv-python)",
      "Bash(\"D:/CTRL_ITERATION/flux-lora-pipeline/backend/venv/Scripts/pip.exe\" install xformers bitsandbytes)",
      "Bash(\"D:/CTRL_ITERATION/flux-lora-pipeline/backend/venv/Scripts/pip.exe\" install --upgrade torchvision torchaudio)",
      "Bash(\"D:/CTRL_ITERATION/flux-lora-pipeline/backend/venv/Scripts/python.exe\" -c \"import torch; print\\(f''PyTorch: {torch.__version__}''\\); print\\(f''CUDA: {torch.cuda.is_available\\(\\)}''\\); print\\(f''GPU: {torch.cuda.get_device_name\\(0\\) if torch.cuda.is_available\\(\\) else \"\"N/A\"\"}''\\)\")",
      "Bash(\"D:/CTRL_ITERATION/flux-lora-pipeline/backend/venv/Scripts/pip.exe\" install torch torchvision torchaudio --index-url https://download.pytorch.org/whl/cu126 --upgrade --force-reinstall)",
      "Bash(\"D:/CTRL_ITERATION/flux-lora-pipeline/backend/venv/Scripts/pip.exe\" install fsspec==2025.10.0)",
      "Bash(\"D:/CTRL_ITERATION/flux-lora-pipeline/backend/venv/Scripts/python.exe\" -c \"from main import app; print\\(''Backend imports successful!''\\)\")",
      "Bash(\"D:/CTRL_ITERATION/flux-lora-pipeline/backend/venv/Scripts/python.exe\" main.py)",
      "Bash(git init:*)",
      "Bash(git add:*)",
      "Bash(git commit:*)",
      "Bash(gh auth status:*)",
      "Bash(gh repo create:*)",
      "Bash(netstat:*)",
      "Bash(findstr:*)",
      "Bash(pkill -f \"cp -r\")",
      "Bash(rsync:*)",
      "Bash(find:*)",
      "Bash(timeout 5 type:*)",
      "Bash(ping:*)",
      "Bash(taskkill:*)",
      "Bash(./venv/Scripts/python.exe:*)",
      "Bash(timeout 3 type:*)",
      "Bash(git push:*)",
      "Bash(curl:*)",
      "Bash(tasklist:*)",
      "Bash(cat:*)",
      "Bash(tee:*)",
      "Bash(\"D:\\\\CTRL_ITERATION\\\\flux-lora-pipeline\\\\backend\\\\venv\\\\Scripts\\\\python.exe\" -c:*)",
      "Bash(\"D:\\\\CTRL_ITERATION\\\\flux-lora-pipeline\\\\backend\\\\venv\\\\Scripts\\\\python.exe\":*)",
      "Bash(timeout /t 1)",
      "Bash(\"D:\\\\CTRL_ITERATION\\\\flux-lora-pipeline\\\\backend\\\\venv\\\\Scripts\\\\python.exe\" -c \"\nimport torch\nfrom diffusers import FluxPipeline\nimport inspect\n\n# Get the _get_add_time_ids or similar method\npipeline = FluxPipeline\ncode = inspect.getsource\\(pipeline\\)\n# Find lines with guidance or pooled\nfor i, line in enumerate\\(code.split\\(''\\\\n''\\)\\):\n    if ''guidance'' in line.lower\\(\\) and \\(''='' in line or ''transformer'' in line\\):\n        print\\(f''{i}: {line.strip\\(\\)[:100]}''\\)\")",
      "Bash(powershell -Command \"Get-Content ''C:\\\\Users\\\\benno\\\\Documents\\\\LoraMachine\\\\backend\\\\training\\\\trainer.py'' | Select-Object -Index 235-245\")",
      "Bash(\"D:/CTRL_ITERATION/flux-lora-pipeline/backend/venv/Scripts/python.exe\" patch_trainer.py)",
      "Bash(\"D:/CTRL_ITERATION/flux-lora-pipeline/backend/venv/Scripts/python.exe\" -c:*)",
      "Bash(\"D:/CTRL_ITERATION/flux-lora-pipeline/backend/venv/Scripts/python.exe\" fix_trainer_final.py)",
      "Bash(\"D:/CTRL_ITERATION/flux-lora-pipeline/backend/venv/Scripts/python.exe\" -c \"\nexec\\(open\\(r''C:\\\\Users\\\\benno\\\\Documents\\\\LoraMachine\\\\fix_trainer_final.py''\\).read\\(\\).replace\\(''\\\\u2713'', ''+''\\)\\)\n\")",
      "Bash(powershell:*)",
      "Bash(timeout:*)",
      "Bash(\"D:\\\\CTRL_ITERATION\\\\flux-lora-pipeline\\\\backend\\\\venv\\\\Scripts\\\\python.exe\" main.py)",
      "Bash(\"D:\\\\CTRL_ITERATION\\\\flux-lora-pipeline\\\\backend\\\\venv\\\\Scripts\\\\python.exe\" \"C:\\\\Users\\\\benno\\\\Documents\\\\LoraMachine\\\\backend\\\\main.py\")",
      "Bash(\"D:/CTRL_ITERATION/flux-lora-pipeline/backend/venv/Scripts/python.exe\" -c \"import main; print\\(''Backend imports successful!''\\)\")",
      "Bash(npm run build:*)",
      "Bash(copy \"C:\\\\Users\\\\benno\\\\OneDrive\\\\Desktop\\\\Dropbox\\\\===PROJECTS AI REFS\\\\CAR STUDIO\\\\fcf23c85721b2afaca3f5123a4642c80.jpg\" \"C:\\\\Users\\\\benno\\\\Documents\\\\LoraMachine\\\\inputs\\\\car_reference.jpg\")",
      "Bash(\"D:/CTRL_ITERATION/flux-lora-pipeline/backend/venv/Scripts/python.exe\" -c \"from inference.img2img_generator import FluxImg2ImgGenerator; print\\(''GGUF img2img generator imported successfully!''\\)\")",
      "Bash(npm run dev:*)",
      "Bash(rm:*)",
      "Bash(del nul)"
    ]
  }
}
